{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.special as sp\n",
    "import os\n",
    "import copy\n",
    "import heapq\n",
    "import json\n",
    "\n",
    "def find_or_create(dirname):\n",
    "    if not os.path.isdir(dirname):\n",
    "        try:\n",
    "            os.makedirs(dirname)\n",
    "        except:\n",
    "            print(\"Cannot create directory : \" + dirname)\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def load_txt(filename):\n",
    "    X = np.loadtxt(filename)\n",
    "    dim = int(X[0]);\n",
    "    size = []\n",
    "    for i in range(dim):\n",
    "        size.append(int(X[i+1]));    \n",
    "    X = np.reshape(X[dim+1:], size, order='F')\n",
    "    return X;\n",
    "        \n",
    "def save_txt(filename, X):\n",
    "    with open(filename, 'w') as f:\n",
    "        y = np.asarray(X)\n",
    "        dim = len(y.shape)\n",
    "        f.write('%d\\n' % dim)\n",
    "        for i in range(dim):\n",
    "            f.write('%d\\n' % y.shape[i])\n",
    "        temp = y.reshape(np.product(y.shape), order='F')\n",
    "        for num in temp:\n",
    "            f.write(str(num)+\"\\n\")\n",
    "        \n",
    "        \n",
    "def normalize(x):\n",
    "    sum_x = np.sum(x)\n",
    "    return np.asarray(x) / sum_x\n",
    "\n",
    "\n",
    "def normalize_exp(x):\n",
    "    return normalize(np.exp(x - np.max(x)))\n",
    "\n",
    "\n",
    "def log_sum_exp(x):\n",
    "    max_x = np.max(x)\n",
    "    return max_x + np.log(np.sum(np.exp(x-max_x)))\n",
    "\n",
    "\n",
    "def psi(x):\n",
    "    return sp.digamma(x)\n",
    "\n",
    "\n",
    "def inv_psi(y):\n",
    "    x = (np.exp(y) + 0.5) * (y > -2.22) + (-1 / (y + 0.577215)) * (y <= -2.22)\n",
    "    for i in range(5):\n",
    "        x = x - ((sp.digamma(x) - y) / sp.polygamma(1, x))\n",
    "    return x\n",
    "\n",
    "\n",
    "def gammaln(x):\n",
    "    return sp.gammaln(x)\n",
    "\n",
    "\n",
    "class Data:\n",
    "    def __init__(self, s=(), h=(), v=()):\n",
    "        self.s = np.asarray(s)\n",
    "        self.h = np.asarray(h)\n",
    "        self.v = np.asarray(v)\n",
    "\n",
    "    def save(self, dirname):\n",
    "        find_or_create(dirname)\n",
    "        if self.s.size > 0:\n",
    "            save_txt(dirname + '/cps.txt', self.s)\n",
    "        if self.h.size > 0:\n",
    "            save_txt(dirname + '/states.txt', self.h)\n",
    "        if self.v.size > 0:\n",
    "            save_txt(dirname + '/obs.txt', self.v)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, dirname):\n",
    "        data = cls()\n",
    "        filename = dirname + '/cps.txt'\n",
    "        if os.path.isfile(filename):\n",
    "            data.s = load_txt(filename)\n",
    "        filename = dirname + '/states.txt'\n",
    "        if os.path.isfile(filename):\n",
    "            data.h = load_txt(filename)\n",
    "        filename = dirname + '/obs.txt'\n",
    "        if os.path.isfile(filename):\n",
    "            data.v = load_txt(filename)\n",
    "        return data\n",
    "\n",
    "\n",
    "class Result:\n",
    "    def __init__(self):\n",
    "        self.cpp = []\n",
    "        self.mean = []\n",
    "        self.ll = []\n",
    "\n",
    "    def save(self, dirname):\n",
    "        find_or_create(dirname)\n",
    "        if len(self.mean) > 0:\n",
    "            save_txt(dirname + '/mean.txt', self.mean)\n",
    "        if len(self.cpp) > 0:\n",
    "            save_txt(dirname + '/cpp.txt', self.cpp)\n",
    "        if len(self.ll) > 0:\n",
    "            save_txt(dirname + '/ll.txt', self.ll)\n",
    "            \n",
    "    @classmethod\n",
    "    def load(cls, dirname):\n",
    "        result = cls()\n",
    "        filename = dirname + '/cpp.txt'\n",
    "        if os.path.isfile(filename):\n",
    "            result.cpp = load_txt(filename)\n",
    "        filename = dirname + '/mean.txt'\n",
    "        if os.path.isfile(filename):\n",
    "            result.mean = load_txt(filename)\n",
    "        filename = dirname + '/ll.txt'\n",
    "        if os.path.isfile(filename):\n",
    "            result.ll = load_txt(filename)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def visualize_data(dirname, m, n):\n",
    "    data = Data.load(dirname)\n",
    "    t = data.v.shape[1]\n",
    "    if m > 0:\n",
    "        fig = plt.figure(figsize=(12, 4))\n",
    "        ax = fig.gca()\n",
    "        ax.pcolormesh(data.v[0:m, :], cmap=plt.cm.Greys)\n",
    "        ax.vlines(np.arange(0, t), 0, data.s * m, colors='r', linestyles='-', linewidth=2)\n",
    "        ax.legend(['change points'])\n",
    "    if n > 0:\n",
    "        fig = plt.figure(figsize=(12, 4))\n",
    "        gs = gridspec.GridSpec(n, 1, height_ratios=np.ones(n))\n",
    "        for i in range(n):\n",
    "            ax = plt.subplot(gs[i])\n",
    "            y = data.v[m + i, :]\n",
    "            y_lim_max = np.max(y) * 1.1\n",
    "            # ax.plot(range(t), y, 'b-')\n",
    "            ax.vlines(np.arange(t), np.zeros(t), y)\n",
    "            ax.vlines(np.arange(0, t), 0, data.s * y_lim_max, colors='r', linestyles='-', linewidth=2)\n",
    "            ax.set_ylim([0, y_lim_max])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Potential:\n",
    "    def __init__(self, alpha=(), a=(), b=(), log_c=0):\n",
    "        self.alpha = np.asarray(alpha, dtype=float)\n",
    "        self.a = np.asarray(a, dtype=float)\n",
    "        self.b = np.asarray(b, dtype=float)\n",
    "        self.log_c = log_c\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.log_c < other.log_c\n",
    "\n",
    "    def __gt__(self, other):\n",
    "        return self.log_c > other.log_c\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        p = copy.deepcopy(self)\n",
    "        p.log_c += other.log_c\n",
    "        # Multiply Dirichlet component\n",
    "        if len(self.alpha) > 0:\n",
    "            p.alpha = self.alpha + other.alpha - 1\n",
    "            p.log_c += gammaln(np.sum(self.alpha)) - np.sum(gammaln(self.alpha))\n",
    "            p.log_c += gammaln(np.sum(other.alpha)) - np.sum(gammaln(other.alpha))\n",
    "            p.log_c += np.sum(gammaln(p.alpha)) - gammaln(np.sum(p.alpha))\n",
    "        # Multiply Gamma components\n",
    "        if len(self.a) > 0:\n",
    "            p.a = self.a + other.a - 1\n",
    "            p.b = (self.b * other.b) / (self.b + other.b)\n",
    "            p.log_c += np.sum(gammaln(p.a) + p.a * np.log(p.b))\n",
    "            p.log_c -= np.sum(gammaln(self.a) + self.a * np.log(self.b))\n",
    "            p.log_c -= np.sum(gammaln(other.a) + other.a * np.log(other.b))\n",
    "        return p\n",
    "\n",
    "    def __str__(self):\n",
    "        np.set_printoptions(precision=3)\n",
    "        buffer = np.concatenate((self.alpha, self.a, self.b, [self.log_c]))\n",
    "        return str(buffer)\n",
    "\n",
    "    @classmethod\n",
    "    def default(cls, m, n):\n",
    "        return cls(np.ones(m), np.ones(n) * 10, np.ones(n), 0)\n",
    "\n",
    "    @classmethod\n",
    "    def from_observation(cls, obs, m, n):\n",
    "        p = cls()\n",
    "        if m > 0:\n",
    "            sum_obs = np.sum(obs[0:m])\n",
    "            p.log_c = gammaln(sum_obs+1) - gammaln(sum_obs+m)\n",
    "            p.alpha = np.asarray(obs[0:m]) + 1\n",
    "        if n > 0:\n",
    "            p.a = np.asarray(obs[m:]) +1\n",
    "            p.b = np.ones(n)\n",
    "        return p\n",
    "\n",
    "    def size(self):\n",
    "        return self.alpha.size + self.a.size\n",
    "\n",
    "    def copy(self):\n",
    "        return copy.deepcopy(self)\n",
    "\n",
    "    def rand(self):\n",
    "        x = np.ndarray(0)\n",
    "        if len(self.alpha) > 0:\n",
    "            x = np.random.dirichlet(self.alpha)\n",
    "        if len(self.a) > 0:\n",
    "            x = np.concatenate((x, np.random.gamma(self.a, self.b, self.a.shape)))\n",
    "        return x\n",
    "\n",
    "    def mean(self):\n",
    "        m = np.ndarray(0)\n",
    "        if len(self.alpha) > 0:\n",
    "            m = normalize(self.alpha)\n",
    "        if len(self.a) > 0:\n",
    "            m = np.concatenate((m, self.a * self.b))\n",
    "        return m\n",
    "\n",
    "    def get_ss(self):\n",
    "        ss = np.ndarray(0)\n",
    "        if len(self.alpha) > 0:\n",
    "            ss = psi(self.alpha) - psi(np.sum(self.alpha))\n",
    "        if len(self.a) > 0:\n",
    "            ss = np.concatenate((ss, self.a * self.b, psi(self.a) + np.log(self.b)))\n",
    "        return ss\n",
    "\n",
    "    def fit(self, ss):\n",
    "        m = len(self.alpha)\n",
    "        n = len(self.a)\n",
    "        if m > 0:\n",
    "            self.alpha = fit_dirichlet_from_ss(ss[0:m])\n",
    "        for i in range(n):\n",
    "            [self.a[i], self.b[i]] = fit_gamma_from_ss([ss[m+i], ss[m+i+n]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Message:\n",
    "\n",
    "    def __init__(self, max_k=100):\n",
    "        self.potentials = []  # potentials\n",
    "        self.h = []           # heap for fast pruning\n",
    "        self.max_k = max_k    # max capacity\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        message = Message()\n",
    "        for p1 in self.potentials:\n",
    "            for p2 in other.potentials:\n",
    "                message.potentials.append(p1 * p2)\n",
    "        return message\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.potentials)\n",
    "\n",
    "    def add_potential(self, p):\n",
    "        k = len(self.potentials)\n",
    "        if k == self.max_k:\n",
    "            k = heapq.heappop(self.h)[1]\n",
    "            self.potentials[k] = p\n",
    "        else:\n",
    "            self.potentials.append(p)\n",
    "        if k > 0:\n",
    "            # push no-change message to heap\n",
    "            heapq.heappush(self.h, (p.log_c, k))\n",
    "\n",
    "    # p(potential)\n",
    "    def pp(self):\n",
    "        return normalize_exp(self.log_c())\n",
    "\n",
    "    # first k potentials belong to change probabilities\n",
    "    def cpp(self, k=1):\n",
    "        return np.sum(self.pp()[:k])\n",
    "\n",
    "    def log_likelihood(self):\n",
    "        return log_sum_exp(self.log_c())\n",
    "\n",
    "    def log_c(self):\n",
    "        return np.asarray([p.log_c for p in self.potentials])\n",
    "\n",
    "    def mean(self):\n",
    "        m = np.asarray([p.mean() for p in self.potentials])\n",
    "        return np.dot(m.transpose(), self.pp())\n",
    "\n",
    "    def get_ss(self):\n",
    "        ss = np.asarray([p.get_ss() for p in self.potentials])\n",
    "        return np.dot(ss.transpose(), self.pp())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, p1, alpha, a, b, max_k=100):\n",
    "        self.p1 = None      # prob. of change\n",
    "        self.log_p1 = None  # log prob. of change\n",
    "        self.log_p0 = None  # log prob. no change\n",
    "        self.max_k = max_k    # maximum number of components\n",
    "        self.set_p1(p1)\n",
    "        self.prior = Potential(alpha, a, b)\n",
    "        self.m = len(alpha)\n",
    "        self.n = len(a)\n",
    "\n",
    "    def set_p1(self, p1):\n",
    "        self.p1 = p1\n",
    "        self.log_p1 = np.log(p1)\n",
    "        self.log_p0 = np.log(1-p1)\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        buffer = load_txt(filename)\n",
    "        p1 = buffer[0]\n",
    "        m = int(buffer[1])\n",
    "        n = int(buffer[2])\n",
    "        alpha = buffer[3:m+3]\n",
    "        a = buffer[3+m:3+m+n]\n",
    "        b = buffer[3+m+n:3+m+n+n]\n",
    "        return cls(p1, alpha, a, b)\n",
    "\n",
    "    @classmethod\n",
    "    def default_model(cls, p1, m, n):\n",
    "        alpha = np.ones(m)\n",
    "        a = np.ones(n) * 10\n",
    "        b = np.ones(n) * 1\n",
    "        return cls(p1, alpha, a, b)\n",
    "\n",
    "    def save(self, filename):\n",
    "        buffer = np.concatenate(([self.p1, self.m, self.n], self.prior.alpha, self.prior.a, self.prior.b))\n",
    "        save_txt(filename, buffer)\n",
    "\n",
    "    def generate_data(self, t):\n",
    "        s = np.random.binomial(1, self.p1, t)               # change points\n",
    "        h = np.zeros((self.m + self.n, t))    # hidden states\n",
    "        v = np.zeros((self.m + self.n, t))    # observations\n",
    "        for i in range(t):\n",
    "            if i == 0 or s[i] == 1:\n",
    "                # generate random state:\n",
    "                h[:, i] = self.prior.rand()\n",
    "            else:\n",
    "                # copy previous state\n",
    "                h[:, i] = h[:, i-1]\n",
    "            # generate observation\n",
    "            v[:, i] = self.rand_obs(h[:, i])\n",
    "        return Data(s, h, v)\n",
    "\n",
    "    def rand_obs(self, state):\n",
    "        obs = np.asarray([])\n",
    "        if self.m > 0:\n",
    "            obs = np.random.multinomial(100, state[0:self.m])\n",
    "        if self.n > 0:\n",
    "            obs = np.concatenate((obs, np.random.poisson(state[self.m:])))\n",
    "        return obs\n",
    "\n",
    "    def predict(self, alpha):\n",
    "        m = Message()\n",
    "        # add change component\n",
    "        m.add_potential(Potential(self.prior.alpha, self.prior.a, self.prior.b, self.log_p1 + alpha.log_likelihood()))\n",
    "        # add no-change components\n",
    "        for p in alpha.potentials:\n",
    "            m.add_potential(Potential(p.alpha, p.a, p.b, p.log_c + self.log_p0))\n",
    "        return m\n",
    "\n",
    "    def update(self, predict, obs):\n",
    "        m = Message(self.max_k)\n",
    "        p_obs = Potential.from_observation(obs, self.m, self.n)\n",
    "        for p in predict.potentials:\n",
    "            m.add_potential(p * p_obs)\n",
    "        return m\n",
    "\n",
    "    def forward(self, obs):\n",
    "        alpha = []\n",
    "        alpha_predict = []\n",
    "        for i in range(obs.shape[1]):\n",
    "            if i == 0:\n",
    "                m = Message()\n",
    "                m.add_potential(Potential(self.prior.alpha, self.prior.a, self.prior.b, self.log_p1))\n",
    "                m.add_potential(Potential(self.prior.alpha, self.prior.a, self.prior.b, self.log_p0))\n",
    "                alpha_predict.append(m)\n",
    "            else:\n",
    "                alpha_predict.append(self.predict(alpha[-1]))\n",
    "            alpha.append(self.update(alpha_predict[-1], obs[:, i]))\n",
    "        return [alpha_predict, alpha]\n",
    "\n",
    "    def backward(self, obs, start=0, length=0):\n",
    "        if length == 0:\n",
    "            length = obs.shape[1]\n",
    "            start = length-1\n",
    "        beta = []\n",
    "        for i in range(start, start - length, -1):\n",
    "            message = Message(self.max_k)\n",
    "            temp = Message()\n",
    "            p_obs = Potential.from_observation(obs[:, i], self.m, self.n)\n",
    "            # change\n",
    "            if len(beta) > 0:\n",
    "                for p in beta[-1].potentials:\n",
    "                    temp.add_potential(p * p_obs)\n",
    "                p_obs.log_c += self.log_p1 + temp.log_likelihood()\n",
    "            message.add_potential(p_obs)\n",
    "            # no change\n",
    "            if len(beta) > 0:\n",
    "                for p in temp.potentials:\n",
    "                    p.log_c += self.log_p0\n",
    "                    message.add_potential(Potential(p.alpha, p.a, p.b, p.log_c))\n",
    "            beta.append(message)\n",
    "        beta.reverse()\n",
    "        return beta\n",
    "\n",
    "    def filter(self, obs, return_message=False):\n",
    "        [alpha_predict, alpha] = self.forward(obs)\n",
    "        # compile result\n",
    "        result = Result()\n",
    "        result.cpp = [message.cpp() for message in alpha]\n",
    "        result.mean = [message.mean() for message in alpha]\n",
    "        result.ll = [alpha[-1].log_likelihood()]\n",
    "        if return_message:\n",
    "            return [result, alpha_predict, alpha]\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "    def smooth(self, obs):\n",
    "        [alpha_predict, alpha] = self.forward(obs)\n",
    "        beta = self.backward(obs)\n",
    "        # compile result\n",
    "        result = Result()\n",
    "        for i in range(len(alpha)):\n",
    "            gamma = alpha_predict[i] * beta[i]\n",
    "            result.cpp.append(gamma.cpp(len(beta[i].potentials)))\n",
    "            result.mean.append(gamma.mean())\n",
    "        result.ll = [alpha[-1].log_likelihood()]\n",
    "        return result\n",
    "\n",
    "    def online_smooth(self, obs, lag):\n",
    "        if lag == 0:\n",
    "            return self.filter(obs)\n",
    "\n",
    "        t = obs.shape[1]\n",
    "        if lag >= t:\n",
    "            return self.smooth(obs)\n",
    "\n",
    "        result = Result()\n",
    "        [alpha_predict, alpha] = self.forward(obs)\n",
    "        beta = []\n",
    "\n",
    "        # Run Fixed-Lag for alpha[0:T - lag]\n",
    "        for i in range(t - lag + 1):\n",
    "            beta = self.backward(obs, i + lag - 1, lag)\n",
    "            gamma = alpha_predict[i] * beta[0]\n",
    "            result.cpp.append(gamma.cpp(len(beta[0])))\n",
    "            result.mean.append(gamma.mean())\n",
    "\n",
    "        # Smooth alpha[T-lag+1:T] with last beta.\n",
    "        for i in range(1, lag):\n",
    "            gamma = alpha_predict[t - lag + i] * beta[i]\n",
    "            result.cpp.append(gamma.cpp(len(beta[i])))\n",
    "            result.mean.append(gamma.mean())\n",
    "\n",
    "        result.ll = [alpha[-1].log_likelihood()]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class TestUtils(unittest.TestCase):\n",
    "\n",
    "    def test_load_save(self):\n",
    "        x = np.random.rand(4, 5)\n",
    "        save_txt('/tmp/x.txt', x)\n",
    "        y = load_txt('/tmp/x.txt')\n",
    "        np.testing.assert_array_almost_equal(x, y)\n",
    "\n",
    "    def test_gammaln(self):\n",
    "        v = np.asarray([1, 2, 3, 4, 5])\n",
    "        gammaln_v = np.asarray([0, 0, 0.693147, 1.791759, 3.178053])\n",
    "        np.testing.assert_array_almost_equal(gammaln(v), gammaln_v)\n",
    "\n",
    "    def test_normalize(self):\n",
    "        v = np.asarray([1, 2, 3, 4, 5])\n",
    "        nv = np.asarray([0.066667, 0.133333, 0.2, 0.266667, 0.333333])\n",
    "        np.testing.assert_array_almost_equal(normalize(v), nv)\n",
    "\n",
    "    def test_normalize_exp(self):\n",
    "        v = np.asarray([1, 2, 3, 4, 5])\n",
    "        log_v = np.log(v)\n",
    "        np.testing.assert_array_almost_equal(normalize(v), normalize_exp(log_v))\n",
    "\n",
    "    def test_log_sum_exp(self):\n",
    "        v = np.asarray([1, 2, 3, 4, 5])\n",
    "        np.testing.assert_array_almost_equal(log_sum_exp(v), np.log(np.sum(np.exp(v))))\n",
    "\n",
    "    def test_psi(self):\n",
    "        v = np.asarray([1, 2, 3, 4, 5])\n",
    "        psi_v = np.asarray([-0.57721566, 0.42278434, 0.92278434, 1.25611767, 1.50611767])\n",
    "        np.testing.assert_array_almost_equal(psi(v), psi_v)\n",
    "\n",
    "    def test_inv_psi(self):\n",
    "        for x in [1e-6, 0.1, 1, 2, 1000]:\n",
    "            np.testing.assert_almost_equal(x, inv_psi(psi(x)))\n",
    "\n",
    "\n",
    "class TestData(unittest.TestCase):\n",
    "\n",
    "    def test_load_save(self):\n",
    "        t = 100\n",
    "        d = 5\n",
    "        data = Data(np.zeros(t), np.random.rand(t, d), np.random.rand(t, d))\n",
    "        data.save('/tmp/data/')\n",
    "        data2 = Data.load('/tmp/data/')\n",
    "        np.testing.assert_array_almost_equal(data.s, data2.s)\n",
    "        np.testing.assert_array_almost_equal(data.h, data2.h)\n",
    "        np.testing.assert_array_almost_equal(data.v, data2.v)\n",
    "\n",
    "\n",
    "class TestModel(unittest.TestCase):\n",
    "\n",
    "    def test_load_save(self):\n",
    "        m = Model(0.01, [1, 1, 1, 1], [10, 10, 10], [1, 1, 1])\n",
    "        m.save('/tmp/model.txt')\n",
    "        m2 = Model.load('/tmp/model.txt')\n",
    "        self.assertEqual(m.p1, m2.p1)\n",
    "        np.testing.assert_array_almost_equal_nulp(m.prior.alpha, m2.prior.alpha)\n",
    "        np.testing.assert_array_almost_equal_nulp(m.prior.a, m2.prior.a)\n",
    "        np.testing.assert_array_almost_equal_nulp(m.prior.b, m2.prior.b)\n",
    "\n",
    "    def test_generate_data(self):\n",
    "        t = 100\n",
    "        # Generate Dirichlet only\n",
    "        m = Model(0.1, [1, 1, 1], [], [])\n",
    "        data = m.generate_data(t)\n",
    "        #data.save('/tmp/data1')\n",
    "\n",
    "        # Generate Gamma only\n",
    "        m2 = Model(0.1, [], [10, 10], [1, 1])\n",
    "        data2 = m2.generate_data(t)\n",
    "        #data2.save('/tmp/data2')\n",
    "\n",
    "        # Generate Coupled\n",
    "        m3 = Model(0.1, [1, 1, 1, 1], [10, 10], [1, 1])\n",
    "        data3 = m3.generate_data(t)\n",
    "        #data3.save('/tmp/data3')\n",
    "\n",
    "\n",
    "class TestPotential(unittest.TestCase):\n",
    "\n",
    "    def test_deepcopy(self):\n",
    "        p1 = Potential.default(3, 2)\n",
    "        p2 = p1.copy()\n",
    "\n",
    "        p2.alpha = np.asarray([1, 2, 3])\n",
    "        p2.a = np.asarray([6, 7])\n",
    "        p2.b = np.asarray([2, 3])\n",
    "        p2.log_c = 2\n",
    "        self.assertNotEqual(p1.log_c, p2.log_c)\n",
    "\n",
    "    def test_comparison(self):\n",
    "        p1 = Potential.default(3, 2)\n",
    "        p2 = Potential.default(3, 2)\n",
    "        p2.log_c = 2\n",
    "        self.assertTrue(p1 < p2)\n",
    "        self.assertTrue(p2 > p1)\n",
    "\n",
    "    def test_multiplication(self):\n",
    "        # Part 1: Test Dirichlet multiplication\n",
    "        p1 = Potential([1, 2, 3, 4], [], [])\n",
    "        p2 = Potential([5, 6, 7, 8], [], [])\n",
    "        p3 = p1 * p2\n",
    "        np.testing.assert_almost_equal(p3.log_c, 2.62466487)\n",
    "        np.testing.assert_array_almost_equal(p3.alpha, np.asarray([5, 7, 9, 11]))\n",
    "\n",
    "        # Part 2: Test Gamma multiplication\n",
    "        p1 = Potential([], [10], [1])\n",
    "        p2 = Potential([], [5], [2])\n",
    "        p3 = p1 * p2\n",
    "        np.testing.assert_almost_equal(p3.log_c, -2.56996487)\n",
    "        np.testing.assert_almost_equal(p3.a, 14)\n",
    "        np.testing.assert_almost_equal(p3.b, 0.66666667)\n",
    "\n",
    "        # Part 2: Test Coupled multiplication\n",
    "        p1 = Potential([1, 2, 3, 4], [10], [1])\n",
    "        p2 = Potential([5, 6, 7, 8], [5], [2])\n",
    "        p3 = p1 * p2\n",
    "        np.testing.assert_almost_equal(p3.log_c, 2.62466487 - 2.56996487)\n",
    "        np.testing.assert_array_almost_equal(p3.alpha, np.asarray([5, 7, 9, 11]))\n",
    "        np.testing.assert_almost_equal(p3.a, 14)\n",
    "        np.testing.assert_almost_equal(p3.b, 0.66666667)\n",
    "\n",
    "    def test_from_observation(self):\n",
    "        obs = np.concatenate((normalize([2, 3, 4, 5]), [7]))\n",
    "        p = Potential.from_observation(obs, 4, 1)\n",
    "        np.testing.assert_array_almost_equal(p.alpha, np.asarray([1.142857, 1.214286, 1.285714, 1.357143]))\n",
    "        np.testing.assert_almost_equal(p.log_c, -3.17805383)\n",
    "        np.testing.assert_almost_equal(p.a, 8)\n",
    "        np.testing.assert_almost_equal(p.b, 1)\n",
    "\n",
    "    def test_mean(self):\n",
    "        p = Potential([1, 2, 3, 4], [10], [1])\n",
    "        np.testing.assert_array_almost_equal(p.mean(), np.asarray([0.1, 0.2, 0.3, 0.4, 10]))\n",
    "\n",
    "    def test_ss(self):\n",
    "        p = Potential([1, 2, 3, 4], [10], [1])\n",
    "        ss = np.asarray([-2.828968, -1.828968, -1.328968, -0.995635, 10., 2.251753])\n",
    "        np.testing.assert_array_almost_equal(p.get_ss(), ss)\n",
    "\n",
    "    '''\n",
    "    def test_rand_and_fit(self):\n",
    "        p = Potential([1, 2, 3, 4], [10, 5], [1, 2])\n",
    "        n = 1000\n",
    "        x = np.zeros((n, 6))\n",
    "        for i in range(n):\n",
    "            x[i, :] = p.rand()\n",
    "        ss1 = np.mean(np.log(x[:, 0:4]), axis=0)\n",
    "        ss2 = np.concatenate((np.mean(x[:, 4:6], axis=0), np.mean(np.log(x[:, 4:6]), axis=0)))\n",
    "        ss = np.concatenate((ss1, ss2))\n",
    "        p2 = Potential.default(4,2)\n",
    "        p2 = p.copy()\n",
    "        p2.fit(ss)\n",
    "   ''' \n",
    "\n",
    "def run_tests():\n",
    "    for m in (TestUtils(),TestData(), TestModel(), TestPotential()):\n",
    "        suite = unittest.TestLoader().loadTestsFromModule(m)\n",
    "        unittest.TextTestRunner().run(suite)\n",
    "        \n",
    "# Comment in for running unit tests\n",
    "# run_tests()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo & Python-C++ Comparison\n",
    "\n",
    "The test below compares the results of the C++ and Python implementations of the Change Point Model. The expectation is that both models give almost equal change point probabilities and expected means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_cpp_python():\n",
    "    bcpm_root = \"../\"\n",
    "    work_dir = '/tmp/demo'\n",
    "    find_or_create(work_dir)\n",
    "    \n",
    "    # save python results\n",
    "    data_dir = os.path.join(work_dir, 'data')\n",
    "    python_dir = os.path.join(work_dir, 'python')\n",
    "    cpp_dir = os.path.join(work_dir, 'cpp')\n",
    "\n",
    "    # Generate Model\n",
    "    t = 30\n",
    "    p1 = 0.05\n",
    "    m = 4\n",
    "    n = 3\n",
    "    model = Model.default_model(p1, m, n)\n",
    "    model.save(work_dir + '/model.txt')\n",
    "\n",
    "    # Generate Data\n",
    "    data = model.generate_data(t)\n",
    "    data.save(data_dir)\n",
    "\n",
    "    # Change Point Estimations\n",
    "    print('filtering...')\n",
    "    result_f = model.filter(data.v)\n",
    "    result_f.save(python_dir + '/filtering')\n",
    "\n",
    "    print('smoothing...')\n",
    "    result_s = model.smooth(data.v)\n",
    "    result_s.save(python_dir + '/smoothing')\n",
    "\n",
    "    print('online smoothing...')\n",
    "    result_o = model.online_smooth(data.v, lag=10)\n",
    "    result_o.save(python_dir + '/online_smoothing')\n",
    " \n",
    "    # Compile c++ code\n",
    "    print('Compiling C++ codes...')\n",
    "    os.system(\"(cd ../cpp/; ./compile)\")\n",
    "    print('Running C++ codes...')\n",
    "    os.system(\"(cd \" + bcpm_root + \"/cpp/bin/; ./runner \" + work_dir + \")\")\n",
    "\n",
    "    cpp_result_f = Result.load(os.path.join(cpp_dir, 'filtering'))\n",
    "    np.testing.assert_array_almost_equal(cpp_result_f.cpp, result_f.cpp, decimal=5)\n",
    "    np.testing.assert_array_almost_equal(cpp_result_f.ll, result_f.ll, decimal=5)\n",
    "\n",
    "    cpp_result_s = Result.load(os.path.join(cpp_dir, 'smoothing'))\n",
    "    np.testing.assert_array_almost_equal(cpp_result_s.cpp, result_s.cpp, decimal=5)\n",
    "    np.testing.assert_array_almost_equal(cpp_result_s.ll, result_s.ll, decimal=5)\n",
    "\n",
    "    cpp_result_o = Result.load(os.path.join(cpp_dir, 'online_smoothing'))\n",
    "    np.testing.assert_array_almost_equal(cpp_result_o.cpp, result_o.cpp, decimal=5)\n",
    "    np.testing.assert_array_almost_equal(cpp_result_o.ll, result_o.ll, decimal=5)\n",
    "    \n",
    "    print('C++ and Python results are almost equal by 5 decimal points.')\n",
    "    \n",
    "    # Visualization\n",
    "    visualize_data(data_dir, m, n)\n",
    "\n",
    "    \n",
    "# Comment in for running C++ vs Python Test\n",
    "# test_cpp_python()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
